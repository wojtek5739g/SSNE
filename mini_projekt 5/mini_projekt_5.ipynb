{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RsbT4aAVQezO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import pickle\n",
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pHAtue4yQezQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8b64n8wmQezR",
        "outputId": "2a85cecc-d910-4c3f-9d74-2f290c149179"
      },
      "outputs": [],
      "source": [
        "with open('p4/train.pkl', 'rb') as train_file:\n",
        "    dataset = pickle.load(train_file)\n",
        "\n",
        "with open('p4/test_no_target.pkl', 'rb') as test_file:\n",
        "    testset = pickle.load(test_file)\n",
        "    \n",
        "# print(dataset)\n",
        "# print(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_ULD_BogQezS",
        "outputId": "0d0d6ba0-088b-41e4-f278-817158b418c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "4756\n",
            "5322\n",
            "592\n"
          ]
        }
      ],
      "source": [
        "print(type(dataset))\n",
        "for i in range(3):\n",
        "    print(len(dataset[i][0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sI_xPluBQezS"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "pad = 0\n",
        "\n",
        "def pad_collate(batch, pad_value=pad):\n",
        "    xx, yy = zip(*batch)\n",
        "    x_lens = [len(x) for x in xx]\n",
        "    y_lens = [1 for y in yy]\n",
        "\n",
        "    # xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
        "    # yy_pad = pad_sequence(yy, batch_first=True, padding_value=pad_value)\n",
        "\n",
        "    xx_pad = pad_sequence([torch.tensor(x) for x in xx], batch_first=True, padding_value=pad_value)\n",
        "    yy_pad = pad_sequence([torch.tensor([y]) for y in yy], batch_first=True, padding_value=pad_value)\n",
        "\n",
        "    return xx_pad, yy_pad, x_lens, y_lens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GSx-tQmAQezT"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "trainset, valset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=5, shuffle=True, collate_fn=pad_collate)\n",
        "val_loader = DataLoader(valset, batch_size=5, shuffle=True, collate_fn=pad_collate)\n",
        "\n",
        "test_loader = DataLoader(testset, batch_size=5, shuffle=False, drop_last=False, collate_fn=pad_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "xuj2EcY1QezU",
        "outputId": "80352f9b-4f82-40b2-ad7d-3e0d1bf18f2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[-1., -1., -1.,  ..., 67., 67., -1.],\n",
            "        [88., 12., 80.,  ...,  0.,  0.,  0.],\n",
            "        [34., 50., 90.,  ...,  0.,  0.,  0.],\n",
            "        [ 0., 12., 92.,  ...,  0.,  0.,  0.],\n",
            "        [-1., -1., -1.,  ...,  0.,  0.,  0.]], dtype=torch.float64), tensor([[1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [3]]), [340, 240, 200, 84, 332], [1, 1, 1, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "print(next(iter(train_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sfS7cBKQSYTv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LSTMClassifier(\n",
              "  (lstm): LSTM(1, 20, num_layers=2)\n",
              "  (linear): Linear(in_features=20, out_features=20, bias=True)\n",
              "  (fc): Linear(in_features=20, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
        "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        return hidden, state\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        all_outputs, hidden = self.lstm(x, hidden)\n",
        "        out = all_outputs[-1] # We are interested only in the last output\n",
        "        x = self.fc(out)\n",
        "        return x, hidden\n",
        "    \n",
        "model = LSTMClassifier(1, 20, 2, 5).to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "m2DeXTlJSZaO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, loss: 1.72\n",
            "Epoch: 20, loss: 1.57\n",
            "Epoch: 40, loss: 1.6\n",
            "Epoch: 60, loss: 1.57\n",
            "Epoch: 80, loss: 1.52\n",
            "Epoch: 100, loss: 1.57\n",
            "Epoch: 0, loss: 1.72\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fun = nn.CrossEntropyLoss()\n",
        "\n",
        "hidden_sizes = [50, 100, 500, 1000]\n",
        "num_layers = [2, 3, 4, 5, 8]\n",
        "\n",
        "for h_s in hidden_sizes:\n",
        "    for n_l in num_layers:\n",
        "        model = LSTMClassifier(1, h_s, n_l, 5).to(device)\n",
        "        for epoch in range(101):\n",
        "            for x, labels, _, _ in train_loader:\n",
        "                x = x.to(device).unsqueeze(2).float()\n",
        "                labels = labels.to(device).squeeze(1)\n",
        "                hidden, state = model.init_hidden(x.size(0))\n",
        "                hidden, state = hidden.to(device), state.to(device) \n",
        "                preds, last_hidden = model(x, (hidden,state))\n",
        "                preds = preds.squeeze(1)\n",
        "                optimizer.zero_grad() \n",
        "                loss = loss_fun(preds, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        \n",
        "            if epoch % 20 == 0:\n",
        "                print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")\n",
        "\n",
        "        file_path = f'model_hs_{h_s}_nl_{n_l}.pt'\n",
        "        torch.save(model.state_dict(), file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# loading model\n",
        "# model.load_state_dict(torch.load(file_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWp763Vxo6yE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 32.14%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, labels, _, _ in val_loader:\n",
        "        x = x.to(device).unsqueeze(2).float()\n",
        "        labels = labels.to(device).squeeze(1)\n",
        "        hidden, state = model.init_hidden(x.size(0))\n",
        "        hidden, state = hidden.to(device), state.to(device) \n",
        "        preds, last_hidden = model(x, (hidden,state))\n",
        "        preds = preds.squeeze(1)\n",
        "\n",
        "        predicted_labels = torch.argmax(preds)\n",
        "        correct = (predicted_labels == labels).sum().item()\n",
        "        total_correct += correct\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "accuracy = total_correct / total_samples * 100\n",
        "print(f\"Accuracy on test set: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "with open('poniedzialek_grunwald_rozkosz.csv', 'w', newline='\\n') as file:\n",
        "    csv_writer = csv.writer(file)\n",
        "\n",
        "    for x, labels, _, _ in test_loader:\n",
        "        x = x.to(device).unsqueeze(2).float()\n",
        "        labels = labels.to(device).squeeze(1)\n",
        "        hidden, state = model.init_hidden(x.size(0))\n",
        "        hidden, state = hidden.to(device), state.to(device) \n",
        "        preds, last_hidden = model(x, (hidden,state))\n",
        "        preds = preds.squeeze(1)\n",
        "\n",
        "        for pred in preds:\n",
        "            csv_writer.writerow([pred])\n",
        "\n",
        "with open('poniedzialek_grunwald_rozkosz.csv', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "with open('poniedzialek_grunwald_rozkosz.csv', 'w') as file:\n",
        "    file.writelines(lines[:-1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
